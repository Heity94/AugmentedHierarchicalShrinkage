{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95a582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26b2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Tree Models from scratch functions\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/TreeModelsFromScratch\")\n",
    "\n",
    "from DecisionTree import DecisionTree\n",
    "from RandomForest import RandomForest\n",
    "#from SmoothShap import verify_shap_model, smooth_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cb555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#import seaborn as sns\n",
    "from imodels import HSTreeClassifier, HSTreeRegressor, HSTreeClassifierCV, HSTreeRegressorCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from copy import deepcopy\n",
    "#from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold\n",
    "#import shap\n",
    "#from shap.explainers._tree import SingleTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31837ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9aa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to imodels-experiment folder\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('../../imodels-experiments')\n",
    "    \n",
    "module_path_imodels = os.getcwd()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path_imodels+\"/config/shrinkage\")\n",
    "    \n",
    "from imodels.util.data_util import get_clean_dataset\n",
    "from datasets import DATASETS_CLASSIFICATION, DATASETS_REGRESSION\n",
    "from util import DATASET_PATH\n",
    "\n",
    "#pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2684bad",
   "metadata": {},
   "source": [
    "# Recreation of results from hierarchical shrinkage paper\n",
    "\n",
    "Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models <br>\n",
    "[Link to paper](https://proceedings.mlr.press/v162/agarwal22b.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d628017",
   "metadata": {},
   "source": [
    ">HS is integrated into the imodels package [imodels](github.com/csinva/imodels) (Singh et al., 2021) with an sklearn compatible API. Experiments for reproducing the results here can be found at [imodels-experiments](github.com/Yu-Group/imodels-experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ddd84",
   "metadata": {},
   "source": [
    "Unfortunately, not all experiments/ figures of the paper can be found in the aforementioned GitHub repository, therefore some of the charts will not be identical to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee5191",
   "metadata": {},
   "source": [
    "## HS performance across various datasets (Fig. 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca591a0",
   "metadata": {},
   "source": [
    "> *Hierarchical Shrinkage (solid lines) often improves predictive performance across various datasets, particularly for small datasets. (A) Top two rows show results for classification datasets (measured by AUC of the ROC curve) and (B) the next two rows show results for regression datasets (measured by R2). HS often significantly improves the performance over CART, CART with CCP, and (C) leaf-based shrinkage. (D) HS even improves results for Random Forests as a function of the number of trees. Across all panels, errors bars show standard error of the mean computed over 10 random data splits. Note that the y-axis scales differ across plots.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c56def",
   "metadata": {},
   "source": [
    "### Create functions to recreate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bdaa3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_scratch(estimator, X, y, cv=10, scoring_func=roc_auc_score, shuffle=True, random_state=None):\n",
    "    \n",
    "    kf = KFold(n_splits=cv, shuffle=shuffle, random_state=random_state)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        # Create true copy of estimator (refitting of scratch models is not possbile)\n",
    "        estimator_copy = deepcopy(estimator)\n",
    "        \n",
    "        #split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #fit estimator, predict & score\n",
    "        estimator_copy.fit(X_train, y_train)\n",
    "        y_pred = estimator_copy.predict(X_test)\n",
    "        scores.append(scoring_func(y_test, y_pred))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de16c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_plot_clf(X, y, cv=10, scoring_func=roc_auc_score, reg_param=100, \n",
    "                                  shuffle=True, random_state=42, dset_name=None, show_adapted_plot=False):\n",
    "\n",
    "    \n",
    "    # Original plot with n_leaves as x-axis\n",
    "    n_leafs = [2,4,6,12,15,18,23,26,27,28,29,30]\n",
    "\n",
    "    cv_res_sk = []\n",
    "    cv_res_im = []\n",
    "\n",
    "    for n_leaf_nodes in n_leafs:\n",
    "\n",
    "        #sklearn\n",
    "        clf_tree_sk = DecisionTreeClassifier(max_leaf_nodes=n_leaf_nodes, random_state=random_state)\n",
    "        cv_res_sk.append(cross_val_score_scratch(clf_tree_sk, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))\n",
    "\n",
    "        #imodels \n",
    "        clf_tree_im = HSTreeClassifier(deepcopy(clf_tree_sk), reg_param=reg_param)\n",
    "        cv_res_im.append(cross_val_score_scratch(clf_tree_im, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))\n",
    "        \n",
    "    #Compute standard error of mean\n",
    "    data_sk = np.array(cv_res_sk)\n",
    "    sem_data_sk = np.std(data_sk, ddof=1, axis=1) / np.sqrt(np.size(data_sk, axis=1))\n",
    "\n",
    "    data_im = np.array(cv_res_im)\n",
    "    sem_data_im = np.std(data_im, ddof=1, axis=1) / np.sqrt(np.size(data_im, axis=1))\n",
    "    \n",
    "    #Create plot\n",
    "    fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "    \n",
    "    fig.suptitle(f\"{dset_name} (n = {X.shape[0]}, p = {X.shape[1]})\")\n",
    "    \n",
    "    axs[0].errorbar(x=n_leafs, y=np.array(data_im).mean(axis=1), yerr=sem_data_im, color=\"tab:blue\", \n",
    "                   alpha=1., linewidth=3, marker=\"o\")\n",
    "    axs[0].errorbar(x=n_leafs, y=np.array(data_sk).mean(axis=1), yerr=sem_data_sk, color=\"tab:blue\", \n",
    "                   alpha=1., linewidth=3, marker=\"o\")\n",
    "\n",
    "    axs[0].set_xlabel(\"number of leaves\")\n",
    "    y_label = \"AUC\" if str(scoring_func).split()[1]==\"roc_auc_score\" else str(scoring_func).split()[1]\n",
    "    axs[0].set_ylabel(y_label)\n",
    "    axs[0].legend([\"hsCART\", \"CART\"])\n",
    "    axs[0].set_title(\"Original plot: n_leaves as x-axis\")\n",
    "    \n",
    "    # if only original plot should be shown\n",
    "    if not show_adapted_plot:\n",
    "        axs[-1].axis('off')\n",
    "        plt.show()\n",
    "        return [[data_sk, sem_data_sk], [data_im, sem_data_im]]\n",
    "    \n",
    "    #Adapted plot with tree_depth as x-axis\n",
    "    tree_depths = range(1,7)\n",
    "\n",
    "    new_cv_res_sk = []\n",
    "    new_cv_res_im = []\n",
    "    new_cv_res_scr = []\n",
    "    new_cv_res_scrHS = []\n",
    "\n",
    "    for depth in tree_depths:\n",
    "\n",
    "        #sklearn\n",
    "        clf_tree_sk = DecisionTreeClassifier(max_depth=depth, random_state=random_state)\n",
    "        new_cv_res_sk.append(cross_val_score_scratch(clf_tree_sk, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))\n",
    "\n",
    "        #imodels \n",
    "        clf_tree_im = HSTreeClassifier(deepcopy(clf_tree_sk), reg_param=reg_param)\n",
    "        new_cv_res_im.append(cross_val_score_scratch(clf_tree_im, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))\n",
    "        \n",
    "        #scratch\n",
    "        clf_tree_scr = DecisionTree(max_depth=depth, random_state=random_state)\n",
    "        new_cv_res_scr.append(cross_val_score_scratch(clf_tree_scr, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))\n",
    "\n",
    "        #scratchHS\n",
    "        clf_tree_scrHS = DecisionTree(max_depth=depth, HShrinkage=True, HS_lambda=reg_param, random_state=random_state)\n",
    "        new_cv_res_scrHS.append(cross_val_score_scratch(clf_tree_scrHS, X, y, cv=cv, scoring_func=scoring_func, \n",
    "                                                 shuffle=shuffle, random_state=random_state))        \n",
    "        \n",
    "    #Compute standard error of mean\n",
    "    new_data_sk = np.array(new_cv_res_sk)\n",
    "    new_sem_data_sk = np.std(new_data_sk, ddof=1, axis=1) / np.sqrt(np.size(new_data_sk, axis=1))\n",
    "\n",
    "    new_data_im = np.array(new_cv_res_im)\n",
    "    new_sem_data_im = np.std(new_data_im, ddof=1, axis=1) / np.sqrt(np.size(new_data_im, axis=1))\n",
    "    \n",
    "    new_data_scr = np.array(new_cv_res_scr)\n",
    "    new_sem_data_scr = np.std(new_data_scr, ddof=1, axis=1) / np.sqrt(np.size(new_data_scr, axis=1))\n",
    "\n",
    "    new_data_scrHS = np.array(new_cv_res_scrHS)\n",
    "    new_sem_data_scrHS = np.std(new_data_scrHS, ddof=1, axis=1) / np.sqrt(np.size(new_data_scrHS, axis=1))\n",
    "    \n",
    "    #Create adapted plot\n",
    "    axs[1].errorbar(x=tree_depths, y=np.array(new_data_im).mean(axis=1), yerr=new_sem_data_im, color=\"tab:blue\", \n",
    "                   alpha=1., linewidth=3, marker=\"o\")\n",
    "    axs[1].errorbar(x=tree_depths, y=np.array(new_data_scrHS).mean(axis=1), yerr=new_sem_data_scrHS, color=\"orange\", \n",
    "                   alpha=1., linewidth=3, marker=\"o\")\n",
    "    axs[1].errorbar(x=tree_depths, y=np.array(new_data_sk).mean(axis=1), yerr=new_sem_data_sk, color=\"tab:blue\", \n",
    "                   alpha=.5, linewidth=3, marker=\"o\")\n",
    "    axs[1].errorbar(x=tree_depths, y=np.array(new_data_scr).mean(axis=1), yerr=new_sem_data_scr, color=\"orange\", \n",
    "                   alpha=.5, linewidth=3, marker=\"o\")\n",
    "\n",
    "\n",
    "    axs[1].set_xlabel(\"Max tree depth\")\n",
    "    y_label = \"AUC\" if str(scoring_func).split()[1]==\"roc_auc_score\" else str(scoring_func).split()[1]\n",
    "    axs[1].set_ylabel(y_label)\n",
    "    axs[1].legend([\"hsCART\", \"hsCART scratch\", \"CART\", \"CART scratch\"])\n",
    "    axs[1].set_title(\"Adapted plot: maximum tree depth as x-axis\")\n",
    "    \n",
    "    plt.show()\n",
    "    return [[data_sk, sem_data_sk], [data_im, sem_data_im]], [[new_data_sk, new_sem_data_sk], [new_data_im, new_sem_data_im], [new_data_scr, new_sem_data_scr], [new_data_scrHS, new_sem_data_scrHS]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21d4fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "dset_name, dset_file, data_source = DATASETS_CLASSIFICATION[1]\n",
    "X, y, feat_names = get_clean_dataset(dset_file, data_source, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_orig, cv_results_new = create_performance_plot_clf(X, y, scoring_func=roc_auc_score, \n",
    "                                                                      reg_param=100, shuffle=True, random_state=42, \n",
    "                                                                      dset_name=dset_name, show_adapted_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63d09f",
   "metadata": {},
   "source": [
    "In the current state of the `TreeModelsfromScratch` there is no parameter to specify the number of leaves per tree. Therefore, we will use tree depth as scale for the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a88e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
