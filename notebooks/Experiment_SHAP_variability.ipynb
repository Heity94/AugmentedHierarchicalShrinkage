{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae46a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bfef773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from TreeModelsFromScratch.DecisionTree import DecisionTree\n",
    "from TreeModelsFromScratch.RandomForest import RandomForest\n",
    "from TreeModelsFromScratch.SmoothShap import verify_shap_model, smooth_shap, GridSearchCV_scratch, cross_val_score_scratch\n",
    "from TreeModelsFromScratch.datasets import DATASETS_CLASSIFICATION, DATASETS_REGRESSION, DATASET_PATH\n",
    "from imodels.util.data_util import get_clean_dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for storing results\n",
    "data_path = os.path.join(os.path.dirname(os.getcwd()),\"data\",\"SHAP_var_experiment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variability of SHAP values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best lambdas for each dataset from Predictive Performance experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambdas_pred_perf():\n",
    "    # Get all files \n",
    "    data_path_predperf = os.path.join(os.path.dirname(os.getcwd()),\"data\",\"pred_perf_experiment\")\n",
    "    data_path_predperf_clf = os.path.join(data_path_predperf, \"classification\")\n",
    "    data_path_predperf_reg = os.path.join(data_path_predperf, \"regression\")\n",
    "\n",
    "    # Define order for datasets\n",
    "    dsets_name_clf = [\"heart\", \"breast-cancer\", \"haberman\", \"diabetes\", \"german-credit\"]\n",
    "    dsets_name_reg = [\"friedman1\", \"friedman2\", \"friedman3\", \"abalone\", \"diabetes-regr\"]\n",
    "\n",
    "    # Get path for all pickle files in classification folderws\n",
    "    pkl_clf = [None] * len(dsets_name_clf)\n",
    "    valid_type = [\".pickle\",\".pkl\"]\n",
    "\n",
    "    for f in os.listdir(data_path_predperf_clf):\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        if ext.lower() not in valid_type:\n",
    "            continue\n",
    "        name = f.split(\"_\")[0]\n",
    "        idx = dsets_name_clf.index(name)\n",
    "        pkl_clf[idx] = os.path.join(data_path_predperf_clf,f)\n",
    "\n",
    "    # Get path for all pickle files in regression folderws\n",
    "    pkl_reg = [None] * len(dsets_name_reg)\n",
    "    valid_type = [\".pickle\",\".pkl\"]\n",
    "\n",
    "    for f in os.listdir(data_path_predperf_reg):\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        if ext.lower() not in valid_type:\n",
    "            continue\n",
    "        name = f.split(\"_\")[0]\n",
    "        idx = dsets_name_reg.index(name)\n",
    "        pkl_reg[idx] = os.path.join(data_path_predperf_reg,f)\n",
    "\n",
    "    # Load clf pickle files\n",
    "    res_clf = {}\n",
    "    for name, i in zip(dsets_name_clf, pkl_clf):\n",
    "        with open(i, \"rb\") as input_file:\n",
    "            res_clf[name]=pickle.load(input_file)\n",
    "\n",
    "    # Load reg pickle files\n",
    "    res_reg = {}\n",
    "    for name, i in zip(dsets_name_reg, pkl_reg):\n",
    "        with open(i, \"rb\") as input_file:\n",
    "            res_reg[name]=pickle.load(input_file)\n",
    "\n",
    "    # Get best lambda values for model with 100 trees\n",
    "    model_names = ['HsRF', 'AugHS_smSHAP', 'AugHS_mse']\n",
    "\n",
    "    # Create dicts for Storing results\n",
    "    lambdas_clf = {k:{j:None for j in model_names} for k in dsets_name_clf}\n",
    "    lambdas_reg = {k:{j:None for j in model_names} for k in dsets_name_reg}\n",
    "    \n",
    "    # Retrieve results\n",
    "    for dset in dsets_name_clf:\n",
    "        for model in model_names:\n",
    "            lambdas_clf[dset][model] = res_clf[dset][model][\"models\"][-2].HS_lambda\n",
    "\n",
    "    for dset in dsets_name_reg:\n",
    "        for model in model_names:\n",
    "            lambdas_reg[dset][model] = res_reg[dset][model][\"models\"][-2].HS_lambda\n",
    "            \n",
    "    return lambdas_clf, lambdas_reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_clf, lambdas_reg = get_lambdas_pred_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heart': {'HsRF': 1, 'AugHS_smSHAP': 0.1, 'AugHS_mse': 10},\n",
       " 'breast-cancer': {'HsRF': 10, 'AugHS_smSHAP': 0.1, 'AugHS_mse': 10},\n",
       " 'haberman': {'HsRF': 0.1, 'AugHS_smSHAP': 0.1, 'AugHS_mse': 10},\n",
       " 'diabetes': {'HsRF': 0.1, 'AugHS_smSHAP': 0.1, 'AugHS_mse': 10},\n",
       " 'german-credit': {'HsRF': 0.1, 'AugHS_smSHAP': 0.1, 'AugHS_mse': 0.1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas_clf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to run experiment and create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23197716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shap_stability_comparison(index_dataset, lambdas_dict=None, treetype=\"classification\", n_estimators=50, n_iter=100, holdout_size=50, random_state=42):\n",
    "    \n",
    "    if lambdas_dict==None:\n",
    "        print(\"please pass lambdas dict!\")\n",
    "        pass\n",
    "    \n",
    "    if treetype==\"classification\":\n",
    "        mtry = \"sqrt\"\n",
    "        dataset = DATASETS_CLASSIFICATION\n",
    "    else:\n",
    "        mtry = 1/3\n",
    "        dataset = DATASETS_REGRESSION\n",
    "    \n",
    "    # Load dataset\n",
    "    dset_name, dset_file, data_source = DATASETS_CLASSIFICATION[index_dataset]\n",
    "    X, y, feat_names = get_clean_dataset(dset_file, data_source, DATASET_PATH)\n",
    "    \n",
    "    #Hold out 50 samples\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=holdout_size, random_state=random_state)\n",
    "    \n",
    "    #Empty array to store shap values\n",
    "    shap_vals = np.empty((n_iter, holdout_size, X_holdout.shape[1], 4))\n",
    "    \n",
    "    # Random seeds\n",
    "    np.random.seed(random_state)\n",
    "    MAX_INT = np.iinfo(np.int32).max\n",
    "    seeds = np.random.randint(MAX_INT, size=100)\n",
    "    \n",
    "    # Create list of models\n",
    "    model_list = [RandomForest(n_trees=n_estimators, n_feature=mtry, treetype=treetype),\n",
    "                  RandomForest(n_trees=n_estimators, n_feature=mtry, treetype=treetype, HS_lambda=lambdas_dict[dset_name][\"HsRF\"], HShrinkage=True),\n",
    "                  RandomForest(n_trees=n_estimators, n_feature=mtry, treetype=treetype, HS_lambda=lambdas_dict[dset_name][\"AugHS_smSHAP\"], oob_SHAP=True, HS_smSHAP=True),\n",
    "                  RandomForest(n_trees=n_estimators, n_feature=mtry, treetype=treetype, HS_lambda=lambdas_dict[dset_name][\"AugHS_mse\"], HS_nodewise_shrink_type=\"MSE_ratio\")]\n",
    "    \n",
    "    model_names = [\"RF\", \"HsRF\", \"AufHsRF_smSHAP\", \"AufHsRF_MSE\"]\n",
    "    \n",
    "    Xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in tqdm(range(n_iter)):\n",
    "        \n",
    "        #Randomly choose 2/3 for training \n",
    "        X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X_train, y_train, test_size=(1/3))\n",
    "        Xs.append(X_train_small)\n",
    "        ys.append(y_train_small)\n",
    "        \n",
    "        for j, model_untrained in enumerate(model_list):\n",
    "            model = deepcopy(model_untrained) #Create deep copy \n",
    "            model.random_state_ = model._check_random_state(seeds[i]) # set random seed so it is equal for all 4 models\n",
    "            model.fit(X_train_small, y_train_small)\n",
    "            export_model = model.export_forest_for_SHAP()\n",
    "            explainer = shap.TreeExplainer(export_model)\n",
    "            shap_vals[i,:,:,j] = explainer.shap_values(X_holdout)\n",
    "    \n",
    "    results = {\n",
    "        \"simulation_settings\":\n",
    "            {\"n_estimators\":n_estimators,\n",
    "            \"treetype\": treetype,\n",
    "            \"n_iter\": n_iter,\n",
    "            \"holdout_size\": holdout_size,\n",
    "            \"lambdas_dict\": lambdas_dict,\n",
    "            \"random_state\": random_state,\n",
    "            \"seeds\": seeds},\n",
    "        \"data\":{\"X\":Xs,\n",
    "                \"y\":ys,\n",
    "                \"X_holdout\":X_holdout,\n",
    "                \"y_holdout\":y_holdout,\n",
    "                \"dset_name\": dset_name,\n",
    "                \"feat_names\": feat_names},\n",
    "        \"SHAP_vals\":shap_vals}\n",
    "    \n",
    "    # Save results as pkl file\n",
    "    with open(f'{data_path}/{dset_name}_SHAP_var.pickle', 'wb') as handle:\n",
    "        pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shap_variability_plot1(results, feat_names_plot=None):\n",
    "\n",
    "    shap_vals = results[\"SHAP_vals\"]\n",
    "    dset_name = results[\"data\"][\"dset_name\"]\n",
    "    feat_names = results[\"data\"][\"feat_names\"]\n",
    "    if feat_names_plot==None:\n",
    "        feat_order = range(len(feat_names)) # for regression we do not have a predefined order\n",
    "    else:\n",
    "        feat_order = [feat_names.index(feat) for feat in feat_names_plot] # for clf we have a predifend order of features to fiully replicate HS paper results\n",
    "\n",
    "    df = pd.DataFrame([shap_vals.var(axis=0).mean(axis=0)[i] for i in feat_order], columns=[\"RF\", \"HsRF\", \"AufHsRF smSHAP\", \"AufHsRF MSE\"])\n",
    "    df[\"feature\"]=feat_names_plot\n",
    "\n",
    "    ax = df.plot(x='feature',\n",
    "            kind='bar',\n",
    "            stacked=False,\n",
    "            title=dset_name,\n",
    "            figsize=(15,5))\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(\"SHAP variability\");\n",
    "\n",
    "    ax.figure.savefig(f\"{data_path}/{dset_name}_plot.png\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HS Classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names for classification plots\n",
    "clf_feat_names_plot = {\n",
    "    \"heart\": [\"att_10\", \"att_3\", \"att_13_1.0\", \"att_12\", \"att_13_-1.0\", \"att_8\", \"att_1\", \"att_9\", \"att_5\", \"att_2\"],\n",
    "    \"breast-cancer\":[\"deg-malig_2.0\", \"inv-nodes\", \"age\", \"tumor-size\", \"breast\", \"node-caps\", \"deg-malig_1.0\", \"deg-malig_0.0\", \"irradiat\", \"breast-quad_0.0\"],\n",
    "    \"haberman\":[\"Number_of_positive_axillary_nodes_detected\", \"Age_of_patient_at_time_of_operation\", \"Patients_year_of_operation\"],\n",
    "    \"diabetes\":[\"A2\", \"A6\", \"A8\", \"A1\", \"A7\", \"A4\", \"A5\", \"A3\"],\n",
    "    \"german-credit\":[\"Status\", \"Credit-history\", \"Duration\", \"Credit\", \"Savings-account\", \"Installment-rate\", \"Property\", \"Personal-status\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [14:09<31:03, 27.01s/it]"
     ]
    }
   ],
   "source": [
    "# run experiment and create plot\n",
    "clf_num = [1,2,3,5,6]\n",
    "for i in clf_num:\n",
    "    results = create_shap_stability_comparison(i, lambdas_dict=lambdas_clf, treetype=\"classification\", n_estimators=50, n_iter=100, holdout_size=50, random_state=42)\n",
    "    dset_name = results[\"data\"][\"dset_name\"]\n",
    "    feat_names_plot = clf_feat_names_plot[dset_name]\n",
    "    create_shap_variability_plot1(results=results, feat_names_plot=feat_names_plot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HS Regression datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiment and create plot\n",
    "reg_num = range(4)\n",
    "for i in reg_num:\n",
    "    results = create_shap_stability_comparison(i, lambdas_dict=lambdas_reg, treetype=\"regression\", n_estimators=50, n_iter=100, holdout_size=50, random_state=42)\n",
    "    dset_name = results[\"data\"][\"dset_name\"]\n",
    "    create_shap_variability_plot1(results=results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create combined plot for all datasets (Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for all datasets\n",
    "def create_shap_variability_plot_all(results):\n",
    "    dfs = []\n",
    "    model_names_plot = [\"RF\", \"HsRF\", \"AufHsRF smSHAP\", \"AufHsRF MSE\"]\n",
    "    dset_names = results.keys()\n",
    "    nrows = len(dset_names)//2\n",
    "    fig, axs = plt.subplots(nrows, 2, figsize=(20,15))\n",
    "\n",
    "    for dset in dset_names:\n",
    "        \n",
    "        shap_vals=results[dset][\"shap_vals\"]\n",
    "        feat_names=results[dset][\"feat_names\"]\n",
    "        feat_order=results[dset][\"feat_order\"]\n",
    "        feat_names_plot=results[dset][\"feat_names_plot\"]\n",
    "        \n",
    "        # Create datafframe to create grouped bar plot\n",
    "        df = pd.DataFrame([shap_vals[j].var(axis=0).mean(axis=0)[i] for i in feat_order], columns=model_names_plot)\n",
    "        df[\"feature\"]=feat_names_plot\n",
    "        dfs.append(df)\n",
    "\n",
    "    idx=0 #for retrieving the correct df\n",
    "    for j in range(nrows):\n",
    "        for i in range(2):\n",
    "            ax = dfs[idx].plot(x='feature',\n",
    "                    kind='bar',\n",
    "                    stacked=False,\n",
    "                    title=dset_names[idx],\n",
    "                    ax=axs[j,i])\n",
    "            ax.xaxis.label.set_visible(False)\n",
    "            ax.set_ylabel(\"SHAP variability\")\n",
    "            idx+=1;\n",
    "\n",
    "    if len(dset_name)%2!=0:\n",
    "        axs[-1].visibility(\"off\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickeled results\n",
    "clf_names = [\"heart\",\"breast-cancer\",\"haberman\",\"diabetes\",\"german-credit\"]\n",
    "clf_plot_combined={}\n",
    "\n",
    "for name in clf_names:\n",
    "    \n",
    "    with open(f'{data_path}/{name}_SHAP_var.pickle', \"rb\") as input_file:\n",
    "        \n",
    "        pkl = pickle.load(input_file)\n",
    "        \n",
    "        shap_vals = pkl[\"SHAP_vals\"]\n",
    "        feat_names = pkl[\"data\"][\"feat_names\"]\n",
    "        feat_order = [feat_names.index(feat) for feat in clf_feat_names_plot[name]]\n",
    "        \n",
    "        clf_plot_combined[name] = {\"shap_vals\":shap_vals, \"feat_names\":feat_names, \"feat_order\":feat_order, \"feat_names_plot\":clf_feat_names_plot[name]}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_shap_variability_plot_all(clf_plot_combined)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickeled results\n",
    "reg_names = [\"friedman1\", \"friedman2\", \"friedman3\", \"abalone\", \"diabetes-regr\"]\n",
    "reg_plot_combined={}\n",
    "\n",
    "for name in reg_names:\n",
    "    \n",
    "    with open(f'{data_path}/{name}_SHAP_var.pickle', \"rb\") as input_file:\n",
    "        \n",
    "        pkl = pickle.load(input_file)\n",
    "        \n",
    "        shap_vals = pkl[\"SHAP_vals\"]\n",
    "        feat_names = pkl[\"data\"][\"feat_names\"]\n",
    "        feat_order = [feat_names.index(feat) for feat in clf_feat_names_plot[name]]\n",
    "        \n",
    "        clf_plot_combined[name] = {\"shap_vals\":shap_vals, \"feat_names\":feat_names, \"feat_order\":feat_order, \"feat_names_plot\":clf_feat_names_plot[name]}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d94c025da75328d2d5dd40c3f3401a47786a54e19e1715d7009c05d4603d2d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
